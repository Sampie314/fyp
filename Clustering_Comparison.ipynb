{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxry83mHre+JfyXmsLXr0p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "hnA_KVuQB2Kl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAM1-XRBBbhp",
        "outputId": "27351188-8e74-4106-85ae-185ba4ad309b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aeon\n",
            "  Downloading aeon-0.10.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting deprecated>=1.2.13 (from aeon)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting numba<0.60.0,>=0.55 (from aeon)\n",
            "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (24.1)\n",
            "Collecting pandas<2.1.0,>=1.5.3 (from aeon)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: scikit-learn<1.5.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (1.3.2)\n",
            "Collecting scipy<1.13.0,>=1.9.0 (from aeon)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from aeon) (4.12.2)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.3.1+cu121)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.5)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->aeon) (1.16.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (71.0.4)\n",
            "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba<0.60.0,>=0.55->aeon)\n",
            "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.1.0,>=1.5.3->aeon) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=1.0.0->aeon) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.0,>=1.0.0->aeon) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=2.1.0->lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.1.0,>=1.5.3->aeon) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.7)\n",
            "Downloading aeon-0.10.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, llvmlite, lightning-utilities, deprecated, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nvidia-cusolver-cu12, aeon, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.0.3 which is incompatible.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aeon-0.10.0 deprecated-1.2.14 lightning-2.4.0 lightning-utilities-0.11.6 llvmlite-0.42.0 numba-0.59.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pandas-2.0.3 pytorch-lightning-2.4.0 scipy-1.12.0 torchmetrics-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install aeon lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from aeon.datasets import load_classification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, conv1x1\n",
        "\n",
        "import lightning as L\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "08Uh2PUGMMn7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/FYP')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRdB8AN2GP4i",
        "outputId": "0082bbbd-161f-4dde-ad03-c355b87fce6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git -C drive/MyDrive/FYP status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mSb2Jja6JPW",
        "outputId": "c856667c-1fa8-4b64-cf76-8b27b6da9344"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refresh index:  66% (2/3)\rRefresh index: 100% (3/3)\rRefresh index: 100% (3/3), done.\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mContrastiveClustering/__pycache__/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git -C drive/MyDrive/FYP pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SK52jxS7El4",
        "outputId": "ed29d19a-a938-4dcc-f8e9-58097b45533b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 4 (delta 1), reused 4 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  25% (1/4)\rUnpacking objects:  50% (2/4)\rUnpacking objects:  75% (3/4)\rUnpacking objects: 100% (4/4)\rUnpacking objects: 100% (4/4), 427 bytes | 7.00 KiB/s, done.\n",
            "From https://github.com/Sampie314/fyp\n",
            "   0a46593..1e35a79  main       -> origin/main\n",
            "Updating 0a46593..1e35a79\n",
            "Fast-forward\n",
            " ContrastiveClustering/ContrastiveCluster.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ContrastiveClustering import ContrastiveCluster as CC"
      ],
      "metadata": {
        "id": "Gs1ZV1SQHQyT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 69\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "MsEiBGqoiaJm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Benchmark Data"
      ],
      "metadata": {
        "id": "mQb-9ja6IPgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Share Price Increase"
      ],
      "metadata": {
        "id": "tFovPU0zIRcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem here is to predict whether a share price will show an exceptional rise after quarterly announcement of the Earning Per Share based on the price movement of that share price on the proceeding 60 days? The data was formatted by Vlad Pazenuks as part of his third year project. Daily price data on NASDAQ 100 companies was extracted from a Kaggle data set. Reporting dates of these companies were obtained from NASDAQ.com. Each data is the percentage change of the close price from the day before. Each case is a series of 60 day data. The target class is is defined as 0 = price did not increase after company report release by more than 5 percent 1 = price increased after company report release by more than 5 percent There are 1931 cases, 1326 class 0 and 605 class 1."
      ],
      "metadata": {
        "id": "Nv0FusU5pn3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "share_price_increase = load_classification('SharePriceIncrease')"
      ],
      "metadata": {
        "id": "Ocjlmv1bkZMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(share_price_increase))\n",
        "share_data, share_labels = share_price_increase\n",
        "# share_labels = share_labels.astype('int')\n",
        "# share_data = torch.tensor(share_data)\n",
        "# share_labels = torch.tensor(share_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMclpZ7tm3Wx",
        "outputId": "496e17ba-c6a3-4d98-ca57-1dab46cfb730"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "share_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu8MrVjQ08IX",
        "outputId": "04a9d5aa-1151-4a2c-f799-195e7ab0d293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', ..., '1', '1', '1'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(share_data, share_labels)\n",
        "dataloader = DataLoader(dataset)"
      ],
      "metadata": {
        "id": "bb_muYm-wlpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(share_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwVXYUi8ps3C",
        "outputId": "db06b3a6-c548-4dc5-fca8-6ea925204fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1931"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(share_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mo7C2qywYE7",
        "outputId": "fb82a2a9-8aa4-4b6d-a466-7940b3bdc295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1931"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXELHgDWqEQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIKWccKPwRwQ",
        "outputId": "2304dd60-ca53-4d54-d187-f5daee0dfd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.TensorDataset at 0x78c6e3c7a080>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(share_data[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-FG4oqpPkk",
        "outputId": "6898b587-411c-4da5-b97b-ffb02619d9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])"
      ],
      "metadata": {
        "id": "urUY9qu6jFta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "share_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9sCdkpQI4bh",
        "outputId": "b87c9a3f-00dd-4c18-c6a4-95361959766c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-4.14537643e+00, -7.70140984e-01,  2.00994691e+00, ...,\n",
              "          5.79414027e-01,  6.43851347e-01,  8.75415202e-01]],\n",
              "\n",
              "       [[-7.49062935e-01,  9.43390794e-01, -1.86911257e-01, ...,\n",
              "          0.00000000e+00, -5.01675748e-01,  2.68908117e+00]],\n",
              "\n",
              "       [[ 4.92917295e+00,  1.06292335e+00,  7.73693641e-01, ...,\n",
              "         -4.89453986e-01, -6.91255106e-01, -1.28505329e+00]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-7.21991939e-01,  7.44954318e-02, -1.46049916e+00, ...,\n",
              "         -2.89349551e+00, -1.68077088e+00,  1.56116505e-01]],\n",
              "\n",
              "       [[-5.66930304e-01, -8.26156696e-01, -2.81597423e-01, ...,\n",
              "         -9.97105542e-01,  6.17291907e-01, -5.05867186e-01]],\n",
              "\n",
              "       [[-7.74558560e-01,  5.83855185e-01, -4.22694555e-03, ...,\n",
              "          2.99329532e-01,  3.00461488e-01, -4.03839405e-03]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "share_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4KuEG6Fi12v",
        "outputId": "f9d867eb-d2d2-4183-93bb-1fdd41f2c39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '0', '0', ..., '1', '1', '1'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(share_data, share_labels, test_size = 0.6, random_state = SEED)"
      ],
      "metadata": {
        "id": "d3Q6E8SlqV8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST"
      ],
      "metadata": {
        "id": "Z4LAPn08otY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
        "\n",
        "kwargs = {}\n",
        "data_loader = DataLoader(full_dataset, batch_size=2, shuffle=True, **kwargs)"
      ],
      "metadata": {
        "id": "ds8fSmscn5NZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (x_i, x_j) in data_loader:\n",
        "    print(x_i)\n",
        "    print(x_j)\n",
        "    # print(_)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWXlOXHisWNd",
        "outputId": "e7967f94-b44d-443a-b681-1e8ece2a5f80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n",
            "tensor([8, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist = datasets.FashionMNIST(root='./data', train=True, download=True)"
      ],
      "metadata": {
        "id": "VxZMoU_fuzs9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms.ToTensor()(fmnist[0][0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW3lywiqu2N4",
        "outputId": "a5cc2ed8-f1a7-45e0-8b86-ef54f102f901"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fmnist[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "JVOQWonEvaR3",
        "outputId": "41a1a022-6056-4800-9d10-10c59d4ac74b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACBUlEQVR4nLXSz0tUURQH8O+597373rx545g6NmNJY6TlJgozEsKFZGCrkDBoVdGmdf9BiwJ3bVr1PwhBUbQfJQcKjWZRTsjo0KDpDPV+eN+997WK0Z2bvtsPfM+Bc4D/HwJycwBZAEAE6zAyfe5RFMQfFYiRAj+CXM/c2HK82VetVMM34RGUmCxz9v7yYnW9dnWyskyHR6azi72Jwep3ScVk9c7LLhKQrpRBSiI2n76puZFT3doUwH4pcmw/zpjrU2zw3dFt4XEWdvbKhpinzTBYt5bDH4qlLYO8cbKBWHOudDHluFtiLrLD0kmM2//6q9VFS+JLLDxv9GzMPV9v3XuzYgHEGSUGCngbRCLd4W6CxPCLHTDwVMkDA0y/qEa/lFFBoF2EEME8CAD6hsZK8+djlmSatuiXXsWfNh27NU6Yelro1bytPElRbaGaO1FGPfc7zPg9HvHlIaVD8AjID9y/+bgZ/6iP9ks7J/QZevh8w/cd2PlGs8CKt92R7MQEk0yA7GtWq9ETN3zRs7fpR7FaWi/3yXaipW1IjFnbaSM70N7dsRzbzbHd8aCx7+wmKskUO5esz0sPmvXYF67gBzoNfxptxb5stxM10iLg1pOTO23NhcUptW1hE6gFYYprC8QMMPNsMM+4pamVbps/HGkSsg+1Cv4d+0Jh//Sm3DjGix4rfwFoJNh2/0cDFgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_std(loader):\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in loader:\n",
        "        # Mean over batch, height and width, but not over the channels\n",
        "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "        num_batches += 1\n",
        "\n",
        "    mean = channels_sum / num_batches\n",
        "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std\n",
        "\n",
        "class ContrastiveFashionMNIST(Dataset):\n",
        "    def __init__(self, root, train=True, transform=None, download=True):\n",
        "        self.fashion_mnist = datasets.FashionMNIST(root=root, train=train, download=download)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.fashion_mnist[index]\n",
        "        img1 = self.transform(img)\n",
        "        img2 = self.transform(img)\n",
        "        return (img1, img2), target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fashion_mnist)\n",
        "\n",
        "def load_fashion_mnist(batch_size, use_cuda=False):\n",
        "    # First, create a DataLoader without normalization\n",
        "    initial_transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    initial_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=initial_transform)\n",
        "    initial_loader = DataLoader(initial_dataset, batch_size=batch_size, num_workers=2, shuffle=False)\n",
        "\n",
        "    # Calculate mean and std\n",
        "    mean, std = get_mean_std(initial_loader)\n",
        "    # print(f\"Calculated mean: {mean.item():.4f}, std: {std.item():.4f}\")\n",
        "\n",
        "    # Now create the full transform with the calculated mean and std\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((mean.item(),), (std.item(),))\n",
        "    ])\n",
        "\n",
        "    train_dataset = ContrastiveFashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = ContrastiveFashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "    full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
        "\n",
        "    kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "    data_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True, drop_last=True, **kwargs)\n",
        "\n",
        "    return data_loader\n"
      ],
      "metadata": {
        "id": "vU67I0dBIkzK"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneity Human Activity Recognition (HHAR)"
      ],
      "metadata": {
        "id": "py8qWh_oIlC7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E3ChJSueIqZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "vOCRSJwRox3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrastive Clustering"
      ],
      "metadata": {
        "id": "Kp9TojVXUzHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available(): print('Using GPU')\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 256\n",
        "feature_dim = 128\n",
        "class_num = 10\n",
        "learning_rate = 0.0003\n",
        "num_epochs = 100\n",
        "instance_temperature = 0.5\n",
        "cluster_temperature = 1.0\n",
        "\n",
        "# Create backbone network\n",
        "backbone = CC.ResNetFashionMNIST(block=BasicBlock, layers=[2, 2, 2, 2])  # ResNet18\n",
        "\n",
        "model = CC.ContrastiveClusteringNetwork(backbone, feature_dim, class_num).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "criterion_instance = CC.InstanceLoss(batch_size, instance_temperature, device).to(device)\n",
        "criterion_cluster = CC.ClusterLoss(class_num, cluster_temperature, device).to(device)\n",
        "\n",
        "# Load Fashion-MNIST dataset\n",
        "data_loader = load_fashion_mnist(batch_size, use_cuda=torch.cuda.is_available())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss = CC.train(model, data_loader, optimizer, criterion_instance, criterion_cluster, device)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "xAuI1exev5f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a873269-59c4-4de2-8e63-c9820b6fae4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 6.5200\n",
            "Epoch [2/100], Loss: 6.3705\n",
            "Epoch [3/100], Loss: 6.3565\n",
            "Epoch [4/100], Loss: 6.3480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Twin Contrastive Learning"
      ],
      "metadata": {
        "id": "qfci5e3hU1gK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SOM"
      ],
      "metadata": {
        "id": "Knmf7h-5U3kN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structural Deep Clustering Network"
      ],
      "metadata": {
        "id": "skkqTI2mU6AX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QjuTQ9eHov99"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}